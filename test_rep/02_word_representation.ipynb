{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "262daef0",
   "metadata": {},
   "source": [
    "### 1. 加载公开词向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81e900a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f69bf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'data/sgns.weibo.word.bz2'\n",
    "model = KeyedVectors.load_word2vec_format(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c266e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "词数:  195202\n",
      "自然语言处理 和 机器学习 的相似度: 0.7483784556388855\n",
      "地铁 和 书本 的相似度: 0.192057266831398\n",
      "与 '上班' 最相似的词有:\n",
      "赶点: 0.6254162192344666\n",
      "下班: 0.6208966374397278\n",
      "车限行: 0.5995197892189026\n",
      "车限号: 0.5659466981887817\n",
      "赶得: 0.5646229982376099\n",
      "收假: 0.558693528175354\n",
      "才醒: 0.5548821091651917\n",
      "倒休: 0.5539935231208801\n",
      "加班: 0.5507659912109375\n",
      "练车: 0.5496417880058289\n"
     ]
    }
   ],
   "source": [
    "# 查询词向量维度\n",
    "print(model.vector_size)\n",
    "\n",
    "# 查看词数\n",
    "print('词数: ', len(model.index_to_key))\n",
    "\n",
    "# 查询某个词的词向量\n",
    "# print('词向量: ', model['自然语言处理'])\n",
    "\n",
    "# 查看两个向量的相似度\n",
    "similarity = model.similarity('自然语言处理', '机器学习')\n",
    "print(f\"自然语言处理 和 机器学习 的相似度: {similarity}\")\n",
    "similarity2 = model.similarity('地铁', '书本')\n",
    "print(f\"地铁 和 书本 的相似度: {similarity2}\")\n",
    "# 找出与某个词最相似的词\n",
    "simmilar_words = model.most_similar(positive=['上班'], topn=10)\n",
    "print(\"与 '上班' 最相似的词有:\")\n",
    "for word, score in simmilar_words:\n",
    "    print(f\"{word}: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ee0299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('女人', 0.6578881740570068),\n",
       " ('女孩子', 0.515068531036377),\n",
       " ('女生', 0.45194485783576965),\n",
       " ('女人真', 0.4420627951622009),\n",
       " ('女人们', 0.43698593974113464)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 男人-男孩+女孩=女人\n",
    "model.most_similar(positive=['男人', '女孩'], negative=['男孩'], topn=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2921208",
   "metadata": {},
   "source": [
    "### 2. 训练自己的词向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "93d247f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import jieba\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8eee969b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>书籍</td>\n",
       "      <td>1</td>\n",
       "      <td>做父母一定要有刘墉这样的心态，不断地学习，不断地进步，不断地给自己补充新鲜血液，让自己保持一...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>书籍</td>\n",
       "      <td>1</td>\n",
       "      <td>作者真有英国人严谨的风格，提出观点、进行论述论证，尽管本人对物理学了解不深，但是仍然能感受到...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>书籍</td>\n",
       "      <td>1</td>\n",
       "      <td>作者长篇大论借用详细报告数据处理工作和计算结果支持其新观点。为什么荷兰曾经县有欧洲最高的生产...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>书籍</td>\n",
       "      <td>1</td>\n",
       "      <td>作者在战几时之前用了＂拥抱＂令人叫绝．日本如果没有战败，就有会有美军的占领，没胡官僚主义的延...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>书籍</td>\n",
       "      <td>1</td>\n",
       "      <td>作者在少年时即喜阅读，能看出他精读了无数经典，因而他有一个庞大的内心世界。他的作品最难能可贵...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cat  label                                             review\n",
       "0  书籍      1  做父母一定要有刘墉这样的心态，不断地学习，不断地进步，不断地给自己补充新鲜血液，让自己保持一...\n",
       "1  书籍      1  作者真有英国人严谨的风格，提出观点、进行论述论证，尽管本人对物理学了解不深，但是仍然能感受到...\n",
       "2  书籍      1  作者长篇大论借用详细报告数据处理工作和计算结果支持其新观点。为什么荷兰曾经县有欧洲最高的生产...\n",
       "3  书籍      1  作者在战几时之前用了＂拥抱＂令人叫绝．日本如果没有战败，就有会有美军的占领，没胡官僚主义的延...\n",
       "4  书籍      1  作者在少年时即喜阅读，能看出他精读了无数经典，因而他有一个庞大的内心世界。他的作品最难能可贵..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('data/online_shopping_10_cats.csv', encoding='utf-8').dropna()\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c4b777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['做', '父母', '一定', '要', '有', '刘墉', '这样', '的', '心态', '，', '不断', '地', '学习', '，', '不断', '地', '进步', '，', '不断', '地', '给', '自己', '补充', '新鲜血液', '，', '让', '自己', '保持', '一颗', '年轻', '的', '心', '。', '我', '想', '，', '这', '是', '他', '能', '很', '好', '的', '和', '孩子', '沟通', '的', '一个', '重要', '因素', '。', '读', '刘墉', '的', '文章', '，', '总能', '让', '我', '看到', '一个', '快乐', '的', '平易近人', '的', '父亲', '，', '他', '始终', '站', '在', '和', '孩子', '同样', '的', '高度', '，', '给', '孩子', '创造', '着', '一个', '充满', '爱', '和', '自由', '的', '生活', '环境', '。', '很', '喜欢', '刘墉', '在', '字里行间', '流露出', '的', '做', '父母', '的', '那种', '小', '狡黠', '，', '让', '人', '总是', '忍俊不禁', '，', '父母', '和', '子女', '之间', '有时候', '也', '是', '一种', '战斗', '，', '武力', '争斗', '过于', '低级', '了', '，', '智力', '较量', '才', '更', '有', '趣味', '。', '所以', '，', '做', '父母', '的', '得', '加把劲', '了', '，', '老', '思想', '老', '观念', '注定', '会', '一败涂地', '，', '生命不息', '，', '学习', '不止', '。', '家庭教育', '，', '真的', '是', '乐在其中', '。'], ['作者', '真有', '英国人', '严谨', '的', '风格', '，', '提出', '观点', '、', '进行', '论述', '论证', '，', '尽管', '本人', '对', '物理学', '了解', '不深', '，', '但是', '仍然', '能', '感受', '到', '真理', '的', '火花', '。', '整本书', '的', '结构', '颇', '有', '特点', '，', '从', '当时', '（', '本', '书写', '于', '八十年代', '）', '流行', '的', '计算机', '话题', '引入', '，', '再用', '数学', '、', '物理学', '、', '宇宙学', '做', '必要', '的', '铺垫', '—', '—', '这些', '内容', '占据', '了', '大部分', '篇幅', '，', '最后', '回到', '关键问题', '：', '电脑', '能', '不能', '代替', '人脑', '。', '和', '现在', '流行', '的', '观点', '相反', '，', '作者', '认为', '人', '的', '某种', '“', '洞察', '”', '是', '不能', '被', '算法', '模拟', '的', '。', '也许', '作者', '想', '说', '，', '人', '的', '灵魂', '是', '无可取代', '的', '。']]\n"
     ]
    }
   ],
   "source": [
    "# 分词 strip() 去除空格/换行符等\n",
    "sentences = [[token for token in jieba.lcut(sentence) if token.strip() !=''] for sentence in df['review']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f6ff8c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62773\n"
     ]
    }
   ],
   "source": [
    "print(len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9d4620de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练Word2Vec模型\n",
    "model = Word2Vec(\n",
    "    sentences,\n",
    "    vector_size=100,\n",
    "    window=5,\n",
    "    min_count=2,\n",
    "    sg=1,\n",
    "    workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a79c0038",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.save_word2vec_format(\"data/word2vec.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3e4ec773",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KeyedVectors.load_word2vec_format(\"data/word2vec.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3d94d3f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.vector_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5621020f",
   "metadata": {},
   "source": [
    "### 3. 词向量应用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ea738791",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "68cd30d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 加载词向量\n",
    "wv = KeyedVectors.load_word2vec_format(\"data/word2vec.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0e148f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<UNK>', '，', '的', '。', '了']\n"
     ]
    }
   ],
   "source": [
    "# 2. 处理OOV\n",
    "unk_token = '<UNK>'\n",
    "index2word = ['<UNK>'] + wv.index_to_key\n",
    "print(index2word[0:5])\n",
    "word2index = {word: index for index, word in enumerate(index2word)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f31ec268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "词表大小: 34577\n",
      "词向量维度: 100\n",
      "(34576, 100)\n"
     ]
    }
   ],
   "source": [
    "# 3. 准备词向量矩阵\n",
    "num_embeddings = len(index2word)\n",
    "print(\"词表大小:\", num_embeddings)\n",
    "embedding_dim = wv.vector_size\n",
    "print(\"词向量维度:\", embedding_dim)\n",
    "\n",
    "embedding_matrix = torch.zeros(num_embeddings, embedding_dim)\n",
    "for idx, word in enumerate(index2word):\n",
    "    if word in wv:\n",
    "        embedding_matrix[idx] = torch.tensor(wv[word])\n",
    "\n",
    "print(wv.vectors.shape)\n",
    "# embadding_matrix = torch.FloatTensor(index2word.vectors)\n",
    "\n",
    "# 4. 创建Embedding层\n",
    "embedding = nn.Embedding.from_pretrained(embedding_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9f8555cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 100])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. 测试\n",
    "text = \"我喜欢乘坐地铁宇宙飞船\"\n",
    "tokens = jieba.lcut(text)  \n",
    "input_ids = [word2index.get(token, word2index[unk_token]) for token in tokens]  \n",
    "input_tensor = torch.tensor([input_ids]) # torch.Size([1, 4]) 包含了batch_size维度\n",
    "embedding(input_tensor).shape "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
